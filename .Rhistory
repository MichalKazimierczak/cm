mu.list <- seq( from=150, to=170 , length.out=200 )
sigma.list <- seq( from=4 , to=20 , length.out=200 )
post2 <- expand.grid( mu=mu.list , sigma=sigma.list )
post2$LL <- sapply( 1:nrow(post2) , function(i)
sum( dnorm( d3 , mean=post2$mu[i] , sd=post2$sigma[i] ,
log=TRUE ) ) )
#4.24
d3 <- sample( d2$height , size=20 )
mu.list <- seq( from=150, to=170 , length.out=200 )
sigma.list <- seq( from=4 , to=20 , length.out=200 )
post2 <- expand.grid( mu=mu.list , sigma=sigma.list )
post2$LL <- sapply( 1:nrow(post2) , function(i)
sum( dnorm( d3 , mean=post2$mu[i] , sd=post2$sigma[i] ,
log=TRUE ) ) )
post2$prod <- post2$LL + dnorm( post2$mu , 178 , 20 , TRUE ) +
dunif( post2$sigma , 0 , 50 , TRUE )
post2$prob <- exp( post2$prod - max(post2$prod) )
sample2.rows <- sample( 1:nrow(post2) , size=1e4 , replace=TRUE ,
prob=post2$prob )
sample2.mu <- post2$mu[ sample2.rows ]
sample2.sigma <- post2$sigma[ sample2.rows ]
plot( sample2.mu , sample2.sigma , cex=0.5 ,
col=col.alpha(rangi2,0.1) ,
xlab="mu" , ylab="sigma" , pch=16 )
dens(sample2.sigma, norm.comp=T)
#4.27
flist<-alist(height~dnorm(mu,sigma),
mu~dnrom(178,20),
sigma~dunif(0,50))
m4.1<-quap(flist,data=d2)
m4.2<-quap(alist(
height~dnorm(mu,sigma),
mu~dnorm(178,0.1),
sigma~dunif(0,50)),
data=d2)
precis(m4.2)
#4.27
flist<-alist(height~dnorm(mu,sigma),
mu~dnorm(178,20),
sigma~dunif(0,50))
m4.1<-quap(flist,data=d2)
precis(m4.1)
mean(d2)
mean(d2$height)
vcov(m4.1)
diag(vcov(m4.1))
cov2cor(vcov(m4.1))
post<-extract.samples(m4.1,n=1e4)
View(post)
precis(m4.1)
precis(post)
precis(m4.1)
#4.37
data(Howell1)
d<-Howell1
d2<-d[d$age>=18,]
plot(d2$height~d2$weight)
###################################################################################################
##################################This script has been created for matching########################
###################################################################################################
library(dplyr)
options(java.parameters = "-Xmx8g")
library(RJDBC)
library(RODBC)
library(RMySQL)
library(data.table)
library(eurostat)
library(tidyr)
library(dplyr)
library(stringr)
library(lubridate)
library(pingr)
library(DBI)
library(dbplyr)
library(odbc)
host<-"ocvwp-dbs017"
port<-3306
dbname<-"patstat2024a"
conn<-paste('jdbc:oracle:thin:@', host, ':', port, '/', sid, sep='')
sid<-"patstat2024a"
###using dbplyr
###This works
con<-dbConnect(odbc::odbc(),
.connection_string='driver={SQL Server};server=ocvwp-dbs017\\PATSTAT;database=patstat2024a;trusted_connection=true')
pat<-dbSendQuery(con,"SELECT tls201_appln.appln_id, tls201_appln.appln_auth,tls201_appln.appln_kind,tls201_appln.appln_filing_date,tls201_appln.appln_filing_year,tls201_appln.ipr_type,
tls201_appln.granted, tls207_pers_appln.person_id, tls206_person.person_name, tls206_person.person_name_orig_lg,
tls206_person.person_address,tls206_person.person_ctry_code,tls206_person.nuts,tls206_person.nuts_level FROM tls201_appln
LEFT JOIN tls207_pers_appln ON tls201_appln.appln_id=tls207_pers_appln.appln_id
LEFT JOIN tls206_person ON tls207_pers_appln.person_id=tls206_person.person_id
WHERE appln_auth IN
('BE','BG','CZ','DK','DE','EE','EP','IE','GR','ES','FR','HR','IT','CY','LV','IT','CY','LV','LT','LU','HU','MT','NL','AT','PL','PT','RO','SI','SK','FI','SE')")
pat<-dbFetch(pat)
saveRDS(pat,"Y:/ESS/IP impact/2024_firm_level/data/IPR_data/PATSTAT/patents.rds")
pat_applicants<-unique(pat[!is.na(pat$person_ctry_code)&pat$person_ctry_code%in%c(eu_countries$code,"GR"),c("person_id","person_name","person_name_orig_lg","person_ctry_code")])
saveRDS(pat_applicants,"Y:/ESS/IP impact/2024_firm_level/data/IPR_data/PATSTAT/patent_applicants.rds")
library(stringr)
library(CleanMatch)
library(data.table)
D_D = "Y:/ESS/IP impact/2024_firm_level/data/IPR_data/PATSTAT"
# D_D is the original data in rds
destf<-"Y:/ESS/IP impact/2024_firm_level/data/IPR_data/PATSTAT/normalized"
###As originally there are two columns that store the names of the applicants: person_name and person_name_orig_lg we want to
###normalize those two columns. For that we will create a dataset storing two versions of names, but only if they are different
##from each other
pat_applicants<-readRDS(paste0(D_D,"/patent_applicants.rds"))
per1<-pat_applicants[,c("person_id","person_name")]
per2<-pat_applicants[,c("person_id","person_name_orig_lg")]
colnames(per2)[2]<-"person_name"
per<-rbind(per1,per2)
per<-unique(per)
pat_applicants<-merge(per,
pat_applicants[,c("person_id","person_ctry_code")],
by="person_id")
check<-readRDS(paste0(destf,"/pat_applicants_normalized.rds"))
pat_applicants<-norma(pat_applicants,"person_name","person_ctry_code","person_id")
View(l)
View(l)
write('PATH="${RTOOLS40_HOME}\\usr\\bin;${C:\\rtools44}"', file = "~/.Renviron", append = TRUE)
devtools::find_rtools()
Sys.which("make")
library(devtools)
install_github("MichalKazimierczak/cm",force=T)
detect_address<-function(r,address,prefix,cc){
data(postal_codes_regex)
data(cities)
r<-data.frame(r)
pcc<-pc[pc$country==cc,]
citiesc<-cities[cities$Country.Code==cc,]
r[,address]<-stringr::str_replace_all(r[,address], "[^a-zA-Zα-ωΑ-Ωa-яA-Я0-9]"," ")
r[,address]<-stringr::str_replace_all(r[,address],"CEDEX"," ")
r[,address]<-stringr::str_replace_all(r[,address],"\\s+"," ")
r[,address]<-stringi::stri_trans_general(r[,address], "latin-ascii; upper")
###first look for postal codes in the address
zip<-stringr::str_extract(r[,address],paste0("(?:^| )?[A-Z]?(?:-| )?",pcc$expres))
r[,address]<-str_replace(r[,address],paste0("(?:^| )?[A-Z]?(?:-| )?",pcc$expres)," ")
zip<-stringr::str_replace(zip,paste0("(?:^| )?[A-Z]?(?:-| )?",pcc$expres),pcc$forma)
zip<-ifelse(is.na(zip),"",zip)
####Finally detect city information in address
citiesc<-cities[cities$Country.Code==cc,]
r$city<-""
for (i in 1:nrow(citiesc)){
cit<-as.character(citiesc[i,"Alternate.Names"])
r$miasto<-ifelse(r$city==""&stringr::str_detect(r[,address],cit),cit,"")
r$city<-ifelse(r$miasto!="",as.character(citiesc[i,"ASCII.Name"]),r$city)
r[,address]<-ifelse(r$miasto!="",str_replace(r[,address],r$miasto,""),r[,address])
r$miasto==""
}
####Now create a vector for street information
r[,paste0(prefix,"_zip")]<-zip
r[,paste0(prefix,"_city")]<-r$city
r[,paste0(prefix,"_street")]<-r[,address]
r$miasto<-NULL
r$city<-NULL
return(r)
}
detect_region<-function(pc,cc){
data(zip_codes)
zipc<-zips[zips$country_code==cc,]
reg<-rep("",length(pc))
for (i in 1:nrow(zipc)){
reg<-ifelse(stringr::str_detect(pc,zipc[i,"CODE"]),paste(reg,zipc[i,"NUTS3"],sep=", "),reg)
}
reg<-stringr::str_remove(reg,"^\\, ")
return(reg)
}
####Continue with Patstat
lista_patstat<-list.files(pattern="patstat")
lista_patstat
options(java.parameters = "-Xmx8g")
library(CleanMatch)
library(stringr)
library(data.table)
library(eurostat)
library(tidyr)
library(plyr)
setwd("Y:/ESS/IP impact/2024_firm_level/data/matched/plain")
####Continue with Patstat
lista_patstat<-list.files(pattern="patstat")
lista_patstat
lista_patstat<-lista_patstat[11:27]
p<-readRDS("Y:/ESS/IP impact/2024_firm_level/data/IPR_data/PATSTAT/patents.rds")
#####Disambiguate national IPR data matching
setwd("Y:/ESS/IP impact/2024_firm_level/data/matched/plain")
nat<-list.files(pattern="nat")
eu<-unique(str_extract(nat,"^.."))
eu
remove(p)
gc()
eu<-eu[11:27]
eu
##read data of firms in the final sample
fs<-readRDS("../../sample/final_sample_23_09_2024.rds")
###and additional information regarding firms in the sample
nat_app<-readRDS("Y:/ESS/IP impact/2024_firm_level/data/IPR_data/national_data/nat_applicants_scrapped.rds")
colnames(nat_app)[6:11]<-paste0("noa_",colnames(nat_app)[6:11])
colnames(nat_app)[c(1,5)]<-c("no","tmdesview_name")
for (cc in eu){
clist<-nat[str_detect(nat,paste0("^",cc))]
n<-data.frame()
for (k in clist){
ip<-str_replace(k,".*([a-z]{3,3})\\.rds","\\1")
nk<-readRDS(k)
nk<-nk[nk$bvd_id_number%in%fs$bvd_id_number,]
ccf<-ifelse(cc%in%c("BE","NL","LU"),"BX",cc)
if(ip=="des"){
apps<-readRDS(paste0("../../IPR_data/national_data/national_designs/nat_des/",tolower(ccf),".rds"))
}else{
apps<-readRDS(paste0("../../IPR_data/national_data/national_trademarks/nat_tms/",tolower(ccf),".rds"))
}
nk<-merge(nk,
apps[,c("applicant_id","ST13")],
by="applicant_id",
all.x=T)
nk<-merge(nk,nat_app,by="ST13",all.x=T)
n<-rbind(n,nk)
}
colnames(n)[6]<-"iso2"
n$iso2.y<-NULL
oa<-readRDS(paste0("Y:/ESS/ORBIS/2023/clean/",cc,"/all_addresses.rds"))
oa<-oa[oa$bvd_id_number%in%n$bvd_id_number,c("bvd_id_number","postcode","city","street_no_building_etc_line_1")]
colnames(oa)<-c("bvd_id_number","orb_postcode","orb_city","orb_street")
oc<-readRDS(paste0("Y:/ESS/ORBIS/2023/clean/",cc,"/contact_info.rds"))
oc<-oc[oc$bvd_id_number%in%n$bvd_id_number,c("bvd_id_number","nuts3")]
oa<-merge(oa,oc,
by="bvd_id_number",
all.x=T)
remove(oc)
gc()
n<-merge(n,oa,by="bvd_id_number",all.x=T)
n$art_key_a<-str_remove_all(n$bvd_id_number,"-.*")
n$bvd_is_root<-ifelse(n$art_key_a==n$bvd_id_number,T,F)
n<-n[n$noa_country==cc,]
saveRDS(n,paste0("enriched/",cc,"_national_ip.rds"))
####For countries with alphabet different from Latin, we will create double entries, one with transliterated address
###and one with address in original alphabet. This will help us in harmonizing city info
if(cc%in%c("CY","GR")){
nh<-n
n$noa_address<-stringi::stri_trans_general(n$noa_address,"Greek-Latin/BGN")
n$noa_address<-stringi::stri_trans_general(n$noa_address, "latin-ascii; upper")
n$noa_street<-stringi::stri_trans_general(n$noa_street,"Greek-Latin/BGN")
n$noa_street<-stringi::stri_trans_general(n$noa_street, "latin-ascii; upper")
n$noa_city<-stringi::stri_trans_general(n$noa_city,"Greek-Latin/BGN")
n$noa_city<-stringi::stri_trans_general(n$noa_city, "latin-ascii; upper")
n$noa_county<-stringi::stri_trans_general(n$noa_county,"Greek-Latin/BGN")
n$noa_county<-stringi::stri_trans_general(n$noa_county, "latin-ascii; upper")
n<-rbind(nh,n)
} else if(cc=="BG"){
nh<-n
n$noa_address<-stringi::stri_trans_general(n$noa_address,"bg-bg_Latn/BGN")
n$noa_address<-stringi::stri_trans_general(n$noa_address, "bg-bg_Latn/BGN")
n$noa_street<-stringi::stri_trans_general(n$noa_street,"bg-bg_Latn/BGN")
n$noa_street<-stringi::stri_trans_general(n$noa_street, "bg-bg_Latn/BGN")
n$noa_city<-stringi::stri_trans_general(n$noa_city,"bg-bg_Latn/BGN")
n$noa_city<-stringi::stri_trans_general(n$noa_city, "bg-bg_Latn/BGN")
n$noa_county<-stringi::stri_trans_general(n$noa_county,"bg-bg_Latn/BGN")
n$noa_county<-stringi::stri_trans_general(n$noa_county, "bg-bg_Latn/BGN")
n<-rbind(nh,n)
}
colnames(n)[17]<-"noa_zip"
n$ApplicantName<-str_replace_all(n$ApplicantName,'\\"|\\„|\\,\\,'," ")
for (i in 14:22){
n[,i]<-str_replace_all(n[,i],'\\"|\\„|\\,\\,'," ")
n[,i]<-str_replace_all(n[,i],"\\,|\\."," ")
n[,i]<-str_trim(n[,i])
}
####conduct additional search for address data in cases where all the information is stored in the address field
gn<-n[!is.na(n$noa_address)&n$noa_address!=""&str_detect(n$noa_address,"[a-zA-Zα-ωΑ-Ωa-яA-Я]")&n$noa_city==""&n$noa_zip=="",]
gna<-n[!n$ST13%in%gn$ST13,]
if (nrow(gn)>0){
gn<-detect_address(gn,"noa_address","noa",cc)
}
n<-rbind(gn,gna)
n<-harmonize_cities(n,"orb_city","noa_city",cc,new_col=F)
nc<-clean(n,"art_key_a","ST13","name","ApplicantName","lf.x","lf.y","orb_postcode","noa_zip","orb_city","noa_city","orb_street","noa_street","nuts3","iso2")
####Now we have to calculate final number associated with each matched pair
dr<-rankmatch(nc,prefer_root = T)
saveRDS(dr,paste0("../disambiguated_sample/",cc,"_orbis_nos.rds"))
gc()
}
detect_region<-function(pc,cc){
data(zip_codes)
zipc<-zips[zips$country_code==cc,]
reg<-rep("",length(pc))
for (i in 1:nrow(zipc)){
reg<-ifelse(stringr::str_detect(pc,zipc[i,"CODE"]),paste(reg,zipc[i,"NUTS3"],sep=", "),reg)
}
reg<-stringr::str_remove(reg,"^\\, ")
return(reg)
}
detect_address<-function(r,address,prefix,cc){
data(postal_codes_regex)
data(cities)
r<-data.frame(r)
pcc<-pc[pc$country==cc,]
citiesc<-cities[cities$Country.Code==cc,]
r[,address]<-stringr::str_replace_all(r[,address], "[^a-zA-Zα-ωΑ-Ωa-яA-Я0-9]"," ")
r[,address]<-stringr::str_replace_all(r[,address],"CEDEX"," ")
r[,address]<-stringr::str_replace_all(r[,address],"\\s+"," ")
r[,address]<-stringi::stri_trans_general(r[,address], "latin-ascii; upper")
###first look for postal codes in the address
zip<-stringr::str_extract(r[,address],paste0("(?:^| )?[A-Z]?(?:-| )?",pcc$expres))
r[,address]<-str_replace(r[,address],paste0("(?:^| )?[A-Z]?(?:-| )?",pcc$expres)," ")
zip<-stringr::str_replace(zip,paste0("(?:^| )?[A-Z]?(?:-| )?",pcc$expres),pcc$forma)
zip<-ifelse(is.na(zip),"",zip)
####Finally detect city information in address
citiesc<-cities[cities$Country.Code==cc,]
r$city<-""
for (i in 1:nrow(citiesc)){
cit<-as.character(citiesc[i,"Alternate.Names"])
r$miasto<-ifelse(r$city==""&stringr::str_detect(r[,address],cit),cit,"")
r$city<-ifelse(r$miasto!="",as.character(citiesc[i,"ASCII.Name"]),r$city)
r[,address]<-ifelse(r$miasto!="",str_replace(r[,address],r$miasto,""),r[,address])
r$miasto==""
}
####Now create a vector for street information
r[,paste0(prefix,"_zip")]<-zip
r[,paste0(prefix,"_city")]<-r$city
r[,paste0(prefix,"_street")]<-r[,address]
r$miasto<-NULL
r$city<-NULL
return(r)
}
options(java.parameters = "-Xmx8g")
library(CleanMatch)
library(stringr)
library(data.table)
library(eurostat)
library(tidyr)
library(plyr)
setwd("Y:/ESS/IP impact/2024_firm_level/data/matched/plain")
lista<-list.files()
##read data of firms in the final sample
fs<-readRDS("../../sample/final_sample_23_09_2024.rds")
###Start with EUIPO disambiguation
lista_euipo<-lista[str_detect(lista,"euipo")]
lista_euipo
lista_euipo<-lista_euipo[16:27]
for (i in lista_euipo){
d<-readRDS(i)
cc<-str_extract(i,"^[A-Z]{2,2}")
d<-d[d$bvd_id_number%in%fs$bvd_id_number,]
###now add address data from respective datasets
oa<-readRDS(paste0("Y:/ESS/ORBIS/2023/clean/",cc,"/all_addresses.rds"))
oa<-oa[oa$bvd_id_number%in%d$bvd_id_number,c("bvd_id_number","postcode","city","street_no_building_etc_line_1")]
colnames(oa)<-c("bvd_id_number","orb_postcode","orb_city","orb_street")
oc<-readRDS(paste0("Y:/ESS/ORBIS/2023/clean/",cc,"/contact_info.rds"))
oc<-oc[oc$bvd_id_number%in%d$bvd_id_number,c("bvd_id_number","nuts3")]
oa<-merge(oa,oc,
by="bvd_id_number",
all.x=T)
remove(oc)
gc()
d<-merge(d,oa,by="bvd_id_number",all.x=T)
#####get data from euipo database
e<-readRDS("Y:/ESS/IP impact/2024_firm_level/data/IPR_data/euipo_owners_2024-03-21.rds")
e<-e[e$OWNER_CODE%in%d$OWNER_CODE,c("OWNER_CODE","ID_TOWN","NM_TOWN","ADOWNER")]
colnames(e)<-c("OWNER_CODE","euipo_postcode","euipo_city","euipo_street")
d<-merge(d,e,by="OWNER_CODE",all.x=T)
d$art_key_a<-str_remove_all(d$bvd_id_number,"-.*")
d$bvd_is_root<-ifelse(d$art_key_a==d$bvd_id_number,T,F)
saveRDS(d,paste0("enriched/",i))
#d<-readRDS(paste0("enriched/",i))
###harmonize the names of the cities in two datasets
d$nuts3<-str_extract(d$nuts3,"^[A-Z]{2,2}[0-9]{3,3}")
d$orb_postcode<-str_trim(d$orb_postcode)
d$euipo_postcode<-str_trim(d$euipo_postcode)
d<-harmonize_cities(d,"orb_city","euipo_city",cc,new_col=F)
dd<-clean(d,"art_key_a","OWNER_CODE","name","OWNER_NAME","lf.x","lf.y","orb_postcode","euipo_postcode","orb_city","euipo_city","orb_street","euipo_street","nuts3","iso2")
####Now we have to calculate final number associated with each matched pair
dr<-rankmatch(dd,prefer_root = F)
saveRDS(dr,paste0("../disambiguated_sample/",cc,"_orbis_euipo.rds"))
}
setwd("Y:/ESS/IP impact/2024_firm_level/data/matched/plain")
lista<-list.files()
##read data of firms in the final sample
fs<-readRDS("../../sample/final_sample_23_09_2024.rds")
###Start with EUIPO disambiguation
lista_euipo<-lista[str_detect(lista,"euipo")]
lista_euipo<-lista_euipo[16:27]
for (i in lista_euipo){
d<-readRDS(i)
cc<-str_extract(i,"^[A-Z]{2,2}")
d<-d[d$bvd_id_number%in%fs$bvd_id_number,]
###now add address data from respective datasets
oa<-readRDS(paste0("Y:/ESS/ORBIS/2023/clean/",cc,"/all_addresses.rds"))
oa<-oa[oa$bvd_id_number%in%d$bvd_id_number,c("bvd_id_number","postcode","city","street_no_building_etc_line_1")]
colnames(oa)<-c("bvd_id_number","orb_postcode","orb_city","orb_street")
oc<-readRDS(paste0("Y:/ESS/ORBIS/2023/clean/",cc,"/contact_info.rds"))
oc<-oc[oc$bvd_id_number%in%d$bvd_id_number,c("bvd_id_number","nuts3")]
oa<-merge(oa,oc,
by="bvd_id_number",
all.x=T)
remove(oc)
gc()
d<-merge(d,oa,by="bvd_id_number",all.x=T)
#####get data from euipo database
e<-readRDS("Y:/ESS/IP impact/2024_firm_level/data/IPR_data/euipo_owners_2024-03-21.rds")
e<-e[e$OWNER_CODE%in%d$OWNER_CODE,c("OWNER_CODE","ID_TOWN","NM_TOWN","ADOWNER")]
colnames(e)<-c("OWNER_CODE","euipo_postcode","euipo_city","euipo_street")
d<-merge(d,e,by="OWNER_CODE",all.x=T)
d$art_key_a<-str_remove_all(d$bvd_id_number,"-.*")
d$bvd_is_root<-ifelse(d$art_key_a==d$bvd_id_number,T,F)
saveRDS(d,paste0("enriched/",i))
#d<-readRDS(paste0("enriched/",i))
###harmonize the names of the cities in two datasets
d$nuts3<-str_extract(d$nuts3,"^[A-Z]{2,2}[0-9]{3,3}")
d$orb_postcode<-str_trim(d$orb_postcode)
d$euipo_postcode<-str_trim(d$euipo_postcode)
d<-harmonize_cities(d,"orb_city","euipo_city",cc,new_col=F)
dd<-clean(d,"art_key_a","OWNER_CODE","name","OWNER_NAME","lf.x","lf.y","orb_postcode","euipo_postcode","orb_city","euipo_city","orb_street","euipo_street","nuts3","iso2")
####Now we have to calculate final number associated with each matched pair
dr<-rankmatch(dd,prefer_root = F)
saveRDS(dr,paste0("../disambiguated_sample/",cc,"_orbis_euipo.rds"))
}
#####get data from euipo database
e<-readRDS("Y:/ESS/IP impact/2024_firm_level/data/IPR_data/euipo_owners_2024-03-21.rds")
#####get data from euipo database
e<-readRDS("Y:/ESS/IP impact/2024_firm_level/data/IPR_data/euipo/euipo_owners_2024-03-21.rds")
for (i in lista_euipo){
d<-readRDS(i)
cc<-str_extract(i,"^[A-Z]{2,2}")
d<-d[d$bvd_id_number%in%fs$bvd_id_number,]
###now add address data from respective datasets
oa<-readRDS(paste0("Y:/ESS/ORBIS/2023/clean/",cc,"/all_addresses.rds"))
oa<-oa[oa$bvd_id_number%in%d$bvd_id_number,c("bvd_id_number","postcode","city","street_no_building_etc_line_1")]
colnames(oa)<-c("bvd_id_number","orb_postcode","orb_city","orb_street")
oc<-readRDS(paste0("Y:/ESS/ORBIS/2023/clean/",cc,"/contact_info.rds"))
oc<-oc[oc$bvd_id_number%in%d$bvd_id_number,c("bvd_id_number","nuts3")]
oa<-merge(oa,oc,
by="bvd_id_number",
all.x=T)
remove(oc)
gc()
d<-merge(d,oa,by="bvd_id_number",all.x=T)
#####get data from euipo database
e<-e[e$OWNER_CODE%in%d$OWNER_CODE,c("OWNER_CODE","ID_TOWN","NM_TOWN","ADOWNER")]
colnames(e)<-c("OWNER_CODE","euipo_postcode","euipo_city","euipo_street")
d<-merge(d,e,by="OWNER_CODE",all.x=T)
d$art_key_a<-str_remove_all(d$bvd_id_number,"-.*")
d$bvd_is_root<-ifelse(d$art_key_a==d$bvd_id_number,T,F)
saveRDS(d,paste0("enriched/",i))
#d<-readRDS(paste0("enriched/",i))
###harmonize the names of the cities in two datasets
d$nuts3<-str_extract(d$nuts3,"^[A-Z]{2,2}[0-9]{3,3}")
d$orb_postcode<-str_trim(d$orb_postcode)
d$euipo_postcode<-str_trim(d$euipo_postcode)
d<-harmonize_cities(d,"orb_city","euipo_city",cc,new_col=F)
dd<-clean(d,"art_key_a","OWNER_CODE","name","OWNER_NAME","lf.x","lf.y","orb_postcode","euipo_postcode","orb_city","euipo_city","orb_street","euipo_street","nuts3","iso2")
####Now we have to calculate final number associated with each matched pair
dr<-rankmatch(dd,prefer_root = F)
saveRDS(dr,paste0("../disambiguated_sample/",cc,"_orbis_euipo.rds"))
}
d<-readRDS(i)
cc<-str_extract(i,"^[A-Z]{2,2}")
d<-d[d$bvd_id_number%in%fs$bvd_id_number,]
oa<-readRDS(paste0("Y:/ESS/ORBIS/2023/clean/",cc,"/all_addresses.rds"))
oa<-oa[oa$bvd_id_number%in%d$bvd_id_number,c("bvd_id_number","postcode","city","street_no_building_etc_line_1")]
colnames(oa)<-c("bvd_id_number","orb_postcode","orb_city","orb_street")
oc<-readRDS(paste0("Y:/ESS/ORBIS/2023/clean/",cc,"/contact_info.rds"))
oc<-oc[oc$bvd_id_number%in%d$bvd_id_number,c("bvd_id_number","nuts3")]
oa<-merge(oa,oc,
by="bvd_id_number",
all.x=T)
e<-readRDS("Y:/ESS/IP impact/2024_firm_level/data/IPR_data/euipo/euipo_owners_2024-03-21.rds")
lista_euipo
lista_euipo<-lista_euipo[2:12]
for (i in lista_euipo){
d<-readRDS(i)
cc<-str_extract(i,"^[A-Z]{2,2}")
d<-d[d$bvd_id_number%in%fs$bvd_id_number,]
###now add address data from respective datasets
oa<-readRDS(paste0("Y:/ESS/ORBIS/2023/clean/",cc,"/all_addresses.rds"))
oa<-oa[oa$bvd_id_number%in%d$bvd_id_number,c("bvd_id_number","postcode","city","street_no_building_etc_line_1")]
colnames(oa)<-c("bvd_id_number","orb_postcode","orb_city","orb_street")
oc<-readRDS(paste0("Y:/ESS/ORBIS/2023/clean/",cc,"/contact_info.rds"))
oc<-oc[oc$bvd_id_number%in%d$bvd_id_number,c("bvd_id_number","nuts3")]
oa<-merge(oa,oc,
by="bvd_id_number",
all.x=T)
remove(oc)
gc()
d<-merge(d,oa,by="bvd_id_number",all.x=T)
#####get data from euipo database
ec<-e[e$OWNER_CODE%in%d$OWNER_CODE,c("OWNER_CODE","ID_TOWN","NM_TOWN","ADOWNER")]
colnames(ec)<-c("OWNER_CODE","euipo_postcode","euipo_city","euipo_street")
d<-merge(d,ec,by="OWNER_CODE",all.x=T)
remove(ec)
d$art_key_a<-str_remove_all(d$bvd_id_number,"-.*")
d$bvd_is_root<-ifelse(d$art_key_a==d$bvd_id_number,T,F)
saveRDS(d,paste0("enriched/",i))
#d<-readRDS(paste0("enriched/",i))
###harmonize the names of the cities in two datasets
d$nuts3<-str_extract(d$nuts3,"^[A-Z]{2,2}[0-9]{3,3}")
d$orb_postcode<-str_trim(d$orb_postcode)
d$euipo_postcode<-str_trim(d$euipo_postcode)
d<-harmonize_cities(d,"orb_city","euipo_city",cc,new_col=F)
dd<-clean(d,"art_key_a","OWNER_CODE","name","OWNER_NAME","lf.x","lf.y","orb_postcode","euipo_postcode","orb_city","euipo_city","orb_street","euipo_street","nuts3","iso2")
####Now we have to calculate final number associated with each matched pair
dr<-rankmatch(dd,prefer_root = F)
saveRDS(dr,paste0("../disambiguated_sample/",cc,"_orbis_euipo.rds"))
}
library(devtools)
install_github("MichalKazimierczak/cm",force=T)
devtools::find_rtools()
library(devtools)
install_github("MichalKazimierczak/cm",force=T)
install.packages("C:/Users/KAZIMMI/Downloads/MichalKazimierczak-cm-561f599.tar.gz")
library(CleanMatch)
setwd("Y:/ESS/IP impact/Functions/cm")
library(roxygen2)
roxygenise()
install.packages("Y:/ESS/IP impact/Functions/cm")
